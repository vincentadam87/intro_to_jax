{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bba0959",
   "metadata": {},
   "source": [
    "# Mnist Classification with Convolutional Neural Networks - with JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a896cab",
   "metadata": {},
   "source": [
    "We start with a few imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import itertools\n",
    "\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad, random\n",
    "rng = random.PRNGKey(0)\n",
    "\n",
    "from jax.example_libraries import optimizers\n",
    "from jax.example_libraries import stax\n",
    "from jax.example_libraries.stax import Dense, Relu, LogSoftmax, Conv, Flatten, Identity\n",
    "\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    !git clone https://github.com/vincentadam87/intro_to_jax.git\n",
    "    import sys  \n",
    "    sys.path.insert(0,'/content/intro_to_jax/notebooks')\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb4175",
   "metadata": {},
   "source": [
    "Setting up a Convolutional Neural Network (CNN) model with stax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e216c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating random inital weights and biases for a neural network\n",
    "\n",
    "# this also creates the forward model of the neural network from image x to class label probability\n",
    "\n",
    "init_random_params, predict = stax.serial(\n",
    "    Conv(16,(3,3), padding=\"SAME\"),\n",
    "    Relu,\n",
    "    Conv(16, (3,3), padding=\"SAME\"),\n",
    "    Relu,\n",
    "    Flatten,\n",
    "    Dense(10),\n",
    "    LogSoftmax\n",
    ")\n",
    "\n",
    "# Note: the parameters will be stored as list of lists (of weight + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff348df",
   "metadata": {},
   "source": [
    "As before we need to declare the loss, accuracy and update functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74da15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss of the classifier: it is the log likelihood of the observations\n",
    "\n",
    "def loss(params, batch):\n",
    "    inputs, targets = batch\n",
    "    preds = predict(params, inputs)\n",
    "    return -jnp.mean(jnp.sum(preds * targets, axis=1))\n",
    "\n",
    "# we can do with a metric a more interpretable metric to evaluate how well we do\n",
    "@jit\n",
    "def accuracy(params, batch):\n",
    "    inputs, targets = batch\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    predicted_class = jnp.argmax(predict(params, inputs), axis=1)\n",
    "    return jnp.mean(predicted_class == target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the update method to run the training loop\n",
    "\n",
    "# Here we don't need to manually code the update. This will be done automatically later!\n",
    "\n",
    "@jit\n",
    "def update(i, opt_state, batch):\n",
    "    params = get_params(opt_state)\n",
    "    return opt_update(i, grad(loss)(params, batch), opt_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4dbec1",
   "metadata": {},
   "source": [
    "Now the main learning routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018cfefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up training parameters\n",
    "step_size = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa329915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data and preprocessing (not that here we don't flatten the images)\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = datasets.mnist(flatten_images=False)\n",
    "num_train = train_images.shape[0]\n",
    "num_complete_batches, leftover = divmod(num_train, batch_size)\n",
    "num_batches = num_complete_batches + bool(leftover)\n",
    "\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7590960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f50930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a data stream to easily get the batches\n",
    "def data_stream():\n",
    "    rng = npr.RandomState(0)\n",
    "    while True:\n",
    "        perm = rng.permutation(num_train)\n",
    "        for i in range(num_batches):\n",
    "            batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
    "            yield train_images[batch_idx], train_labels[batch_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63837a23",
   "metadata": {},
   "source": [
    "Now the main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c96f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we initiate a SGD optimizer which provides the update function\n",
    "opt_init, opt_update, get_params = optimizers.sgd(step_size)\n",
    "\n",
    "\n",
    "batches = data_stream()\n",
    "\n",
    "_, init_params = init_random_params(rng, (-1, 28, 28, 1))\n",
    "opt_state = opt_init(init_params)\n",
    "itercount = itertools.count()\n",
    "\n",
    "# now iterate over epoch\n",
    "# for each epoch, iterate over batches\n",
    "# and update the weights\n",
    "# at the end of the epoch print the training and test accuracies\n",
    "\n",
    "# <SOLUTION\n",
    "print(\"\\nStarting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_batches):\n",
    "        if _%50 == 0:\n",
    "            print('epoch %d/%d'%(epoch, num_epochs), 'batch: %d/%d'%(_, num_batches))\n",
    "        opt_state = update(next(itercount), opt_state, next(batches))\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    params = get_params(opt_state)\n",
    "    train_acc = accuracy(params, (train_images, train_labels))\n",
    "    test_acc = accuracy(params, (test_images, test_labels))\n",
    "    print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
    "    print(f\"Training set accuracy {train_acc}\")\n",
    "    print(f\"Test set accuracy {test_acc}\")\n",
    "    \n",
    "# SOLUTION>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0b5ff5",
   "metadata": {},
   "source": [
    "# Interpreting the convolutional weights\n",
    "\n",
    "Convolutional neural networks were inspired by receptive fields in visual area V1 of the brain.\n",
    "\n",
    "We know that the visual system consists of a sequence of feature extractors,\n",
    "starting from simple line, edge detectors.\n",
    "\n",
    "Convolutional neural networks learn similar strategies from data!\n",
    "Let's look at the learned feature extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the weights of the first layer (the one directly applied to the input image)\n",
    "\n",
    "# hint:  weights for the first layer are in params[0][o]\n",
    "\n",
    "# <SOLUTION\n",
    "fig, axarr = plt.subplots(4,4)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        n = i*4 + j\n",
    "        axarr[i,j].imshow(params[0][0][:,:, 0, n])\n",
    "plt.show()\n",
    "# SOLUTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4359523",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* Can you see the edge detector?\n",
    "* Play with different architectures, can you get a better accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
